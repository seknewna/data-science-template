{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Tools in Python\n",
    "-----\n",
    "In this tutorial, you will learn about available software packages in Python which are used by data scientists. The ideal persona for this tutorial is a person who has never used Python and is curious to explore whats available. The idea here is to introduce you to available resources in Python rather than teach you details on how to use as a specific package.  For selected packages, a simple example will be provided to demonstrate usage. Otherwise, most packages will be listed for the leaner to explore in their own time. However, we will use some of the packages in later sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "- [Learning Outcomes](#Learning Outcomes)\n",
    "- [General Purpose Data Wrangling](#General Purpose Data Wrangling)\n",
    "    - [Pandas](#Pandas)\n",
    "    - [Numpy](#Numpy)\n",
    "    - [Apache Spark for Large scale data processing](#Apache Spark for Large scale data processing)\n",
    "- [Web Scraping](#Web Scraping)\n",
    "- [Natural Language Processing](#Natural Language Processing)\n",
    "    - [NTLK](#Navigation)\n",
    "- [Geospatial Data](#Geospatial Data)\n",
    "    - [GDAL](#GDAL)\n",
    "    - [Geopandas](#Geopandas)\n",
    "    - [Shapely](#Shapely)\n",
    "    - [Rasterio](#Rasterio)\n",
    "- [Statistical Analysis and Optimisation](#Statistical Analysis and Optimisations)\n",
    "    - [scipy](#scipy)\n",
    "    - [Numpy](#Numpy)\n",
    "    - [statsmodels](#statsmodels)\n",
    "- [Machine Learning](#Machine Learning)\n",
    "    - [sciki-learn](#sciki-learn)\n",
    "    - [Tensorflow](#Tensorflow)\n",
    "    - [Theano](#Theano)\n",
    "- [Data Visualization](#Data Visualization)\n",
    "    - [Matplotlib](#Matplotlib)\n",
    "    - [Seaborn](#SNS)\n",
    "    - [Bokeh](#Bokeh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Outomes\n",
    "After going through this notebook, the leaner should:\n",
    "- Be familiar with  Python packages for the following purposes:\n",
    "    - Data wrangling\n",
    "    - Statistical data analysis\n",
    "    - Data visualization\n",
    "    - Natural language processing\n",
    "    - Geospatial data processing and visualization\n",
    "    - Machine Learning\n",
    "- Appreciate the Python package ecoystem for data science\n",
    "- Use import statement to import packages and perfom simple tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Purpose Data Wrangling\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this category, we look at Python libraries which can be used to perfom the most common data wrangling tasks such as data ingestion, data cleaning, subsetting data, recoding variables, checking for missing values, imputing missing values, exploring distributions and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Pandas is a library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. Pandas is free software released under the three-clause BSD license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Data Structures in Pandas\n",
    "Pandas has two mainndata structures as follows: Series, DataFrames and Panels.\n",
    "1. **Series:** A 1-dimensional labelled array that can hold data of any type (integer, string, float, python objects, etc.). \n",
    "    It’s axis labels are collectively called an index.\n",
    "2. **DataFrame:** A 2-dimensional labelled data structure with columns and both a row and a column index. A dataframe can \n",
    "    be used to represent 3-D data using multiindexing. \n",
    "    \n",
    "A dataframe is often abbreviated as ```df```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['Dunstan','Mercy','Khama','Lara','Khali','Gloria']\n",
    "names = pd.Series(data)\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Series Using a Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\":['Dunstan','Mercy','Khama','Lara','Khali','Gloria']}\n",
    "names = pd.Series(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\":['Dunstan','Mercy','Khama','Lara','Khali','Gloria'],\n",
    "       \"age\": [100, 20, 7, 11, 30, 88]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion with Pandas: A Case of CSV file\n",
    "Pandas can work with many data stores and file formats. To take a quick look at what file formats pandas can read, type ```pd.read``` and then hit tab, you should see a list of all the file formats supported by pandas. In this example, we show reading from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas package\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the name of the CSV file\n",
    "data_file = \"../data/power-outages.csv\"\n",
    "\n",
    "# Read data into dataframe\n",
    "# dataframe is the pandas object for handling tabular data\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/power-outages.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [{'name':'Dunstan', 'age':50}, {'name':'Khama', 'age':1}]\n",
    "df_from_list = pd.DataFrame(my_data)\n",
    "df_from_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data\n",
    "Once you have read the data, pandas has many functions to allow you explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the n-top rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes and other info about the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics if it makes sense\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df[\"str_datetime_sent_hr\"]\n",
    "type(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "print(type(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps with Pandas\n",
    "Please refer to pandas [documentation](http://pandas.pydata.org/pandas-docs/stable/10min.html) for tutorials on how to perfom various tasks such as indexing rows, subsetting the data, chaning column names and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**Numpy** is one of the underlying libraries which powers many high level packages such as pandas. In most case, you will not need to interact with **Numpy** directly but its an essential package for data manipulation and scientific computing in Python. Its useful for linear algebra, Fourier transform, and random number capabilities because it has advanced array/matrix functionalities. Also, most of the machine learning packages do require input as **Numpy** arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays in Numpy\n",
    "In the code below, we show how **Numpy** arrays work seamlessly with pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = df.lat.values\n",
    "type(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for i in range(5, 3, 15):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Numpy\n",
    "import numpy as np\n",
    "\n",
    "# create two arrays\n",
    "x = np.array([i + 100 for i in range(10)])\n",
    "y = np.array([i -10 for i in range(10)])\n",
    "\n",
    "# create a dictionary with key as column name and value as the numpy arrays\n",
    "data = {\"x\": x, \"y\":y}\n",
    "\n",
    "# Use the dictinary to create a pandas dataframe\n",
    "df_from_np = pd.DataFrame(data)\n",
    "\n",
    "# Check out the dataframe\n",
    "df_from_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array([1,2,3])\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([i + 100 for i in range(10)])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers = pd.read_csv(data_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers.columns.names = ['psu', 'lon', 'lat', 'str_datetime_sent_hr', 'power_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers.rename(columns={0:\"psu\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out Numpy Documentation for Additional Details\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "[Numpy documentation](https://docs.scipy.org/doc/numpy/user/quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallell Data Processing\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "When you have large datasets regular packages such as pandas do not scale very well. For instance, \n",
    "even a 5gb dataset can't be handled gracefully by pandas. When you have these large datasets, \n",
    "you look for packages which can parellilze processing and make things faster. In Python, they \n",
    "are many tools for parallell data processing as follows:\n",
    "- [Apache Spark](https://spark.apache.org): this probably the most popular framework for distributed data processing\n",
    "- [Dask](http://docs.dask.org/en/latest/why.html): This library offers code parallelisation \n",
    "    utilising existing libraries such as pandas\n",
    "- [Python Multiprocessing Library](https://docs.python.org/3.4/library/multiprocessing.html?highlight=process): Python offers a multiprocessing library but it requires people \n",
    "    who are more experienced with programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Power of Apache Spark\n",
    "In the example below, lets see how fast things can get when we use Apache Spark compared to Pandas. Please pay attention to the time taken to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# A utility function for measuring execution \n",
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "def timefn(fn):\n",
    "    @wraps(fn)\n",
    "    def measure_time(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = fn(*args, **kwargs)\n",
    "        t2 = time.time()\n",
    "        print(\"@timefn:\" + fn.__name__ + \" took \" + str(t2 - t1) + \" seconds\")\n",
    "        return result\n",
    "    return measure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# we add @timefn to measure execution time of the function\n",
    "@timefn\n",
    "def load_big_csv_with_apache_spark(big_csv=None):\n",
    "    \"\"\"\n",
    "    A simple function which loads a CSV file using Apache Spark and\n",
    "    then counts how many rows are in the file\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.master(\"local[12]\").appName(\"data_processor\").getOrCreate()\n",
    "    df = spark.read.csv(big_csv)\n",
    "    cnt = df.count()\n",
    "    print('Number of rows in big CSV file: {:,}'.format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@timefn\n",
    "def load_big_csv_with_pandas(big_csv=None):\n",
    "    \"\"\"\n",
    "    Use pandas library to load the large CSV\n",
    "    \"\"\"\n",
    "    # Read CSV as a dataframe (df) here\n",
    "    df = pd.read_csv(big_csv)\n",
    "    \n",
    "    # Get the total number of rows\n",
    "    cnt = df.shape[0]\n",
    "    print('Done with counting')\n",
    "    \n",
    "    # Get total number of unique activities using 'SID' column using code below\n",
    "    uniq_SID = list(df['SID'].unique())\n",
    "    print('Done with unique values')\n",
    "    \n",
    "    # Use len() function to get number of elements in the list above\n",
    "    cnt_uniq = len(uniq_SID)\n",
    "    \n",
    "    # print out the results\n",
    "    print('Number of rows in big CSV file: {:,}, Number of unique activities: {}'.format(cnt,cnt_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import APache Spark relevant library\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# the task is to read in an 8GB CSV file and then count number of rows\n",
    "big_csv_file = os.path.abspath(\"/Users/dmatekenya/Google-Drive/gigs/un-siap-2018/ch3-big-data-processing/data/activity_log_raw.csv\")\n",
    "load_big_csv_with_apache_spark(big_csv=big_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using pandas\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "print('Pandas starting now {}'.format(start.ctime()))\n",
    "load_big_csv_with_pandas(big_csv=big_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We often have to deal with data which is geospatial in nature or has geographic coordinates. Python has a suite of tools for handling spatial data as we will show in the next section.\n",
    "- [GDAL](https://www.gdal.org): this is one of the core libraries for provising geospatial data functionality. Most of the other libraries are based on GDAL.\n",
    "- [Geopandas](http://geopandas.org): A pandas version for geospatial data\n",
    "- [Shapely](https://shapely.readthedocs.io/en/stable/manual.html): yet another spatial data library with alot of functionalities.\n",
    "- [Rasterio](https://rasterio.readthedocs.io/en/latest/quickstart.html): this library fosues on raster data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Shapefiles with GDAL OGR Library\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "GDAL s a translator library for raster and vector geospatial data formats that is released under an X/MIT style Open Source license by the Open Source Geospatial Foundation. Its also used in oen source GIS software such as QGIS. In Python, you can use the library to read raster and vector data as well as manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import ogr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from osgeo import ogr\n",
    "\n",
    "# shapefile path\n",
    "shp_file = '../data/Balaka_EA.shp'\n",
    "\n",
    "# open shapefile\n",
    "file = ogr.Open(shp_file)\n",
    "shape = file.GetLayer(0)\n",
    "\n",
    "#first feature of the shapefile\n",
    "feature = shape.GetFeature(0)\n",
    "\n",
    "# Convert first feature to GeoJSON\n",
    "first = feature.ExportToJson()\n",
    "\n",
    "# print the JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(shp_file)\n",
    "gdf.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Spatial Data with Geopandas\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "GeoPandas is an open source project to make working with geospatial data in python easier. GeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "# read the shapefile which we arleady defined in cells above\n",
    "df = gpd.read_file(shp_file)\n",
    "\n",
    "# diplay the shapefile \n",
    "display(df.plot(figsize=(8, 8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Geospatial Data Libraries\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "They are other essential packages to handle spatial data in Python including:\n",
    "- [Fiona](https://fiona.readthedocs.io/en/stable/): Geopandas uses this library behind the scenes\n",
    "- [Descartes](https://bitbucket.org/sgillies/descartes/): For spatial data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis and Optimisations\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are interested in more sophisticated statistical analysis, Python also offers further tools in addtion to packages like Pandas which also has basic statistical functionalities. Here, we look at the following packages:\n",
    "- [Statsmodels](https://www.statsmodels.org/stable/index.html): For more rigorous statistical analysis than found in Pandas\n",
    "- [Scipy](): This is part of the Python scientific computing stack which also includes Numpy\n",
    "- [Numpy](): Arleady mentioned above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Estimation with StatsModels\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration.Refer to [documentation](https://www.statsmodels.org/stable/index.html) for further details. The example　below has been adopted from StatsModels documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "nsample = 1000\n",
    "x = np.linspace(0, 10, 1000)\n",
    "X = np.column_stack((x, x**2))\n",
    "beta = np.array([1, 0.1, 10])\n",
    "e = np.random.normal(size=nsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "y = np.dot(X, beta) + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Python has become the lingua franca for many data science applications including Machine Learning. It therefore comes as no surprise that its one of the leading scripting langueages when it comes to machine learning. The top machine learning packages in Python based on usage include:\n",
    "- [scikit-learn](https://scikit-learn.org/stable/): This is a general purpose machine learning library and it can be used for diverse machine tasks unlike other libraries which may be more specialised. \n",
    "- [Tensorflow](https://www.tensorflow.org): this library is focused on deep learning and other neural networks approaches\n",
    "- [Keras](http://keras.io): Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow and Theano\n",
    "- [Theano](http://deeplearning.net/software/theano/): Also focused on deep learning and neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "A lot of unstructured data is available on the internet. Once gathered and put into a structured & meaningful format, this data can be used to perform analytics and derive meaningful insights. In this tutorial, I am going to demonstrate how we can collect such data from the internet and process it to get it to be in a structured format. This process is known as Web Scraping. It is also called Screen Scraping, Web Harvesting or Web Data Extraction. In Python, they are many packages for web scraping but the most common ones include:\n",
    "- [requests](http://docs.python-requests.org/en/master/): A library that fetches the content of the URL.\n",
    "- [Beatifulsoup](https://www.crummy.com/software/BeautifulSoup/): A library that allows you to parse the HTML source code in a beautiful way.\n",
    "- [Scrapy](https://scrapy.org): An out of the box solution for web scraping with other advanced functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Sneak Peak at Requests\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_url = \"https://www.kdnuggets.com/2018/02/top-news-week-0129-0204.html\"\n",
    "r = requests.get(web_url)\n",
    "c = r.content\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And BS to parse the html\n",
    "soup = BeautifulSoup(c,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use request to get contents od webpage\n",
    "r = requests.get(\"https://www.kdnuggets.com/2018/02/top-news-week-0129-0204.html\")\n",
    "c = r.content\n",
    "\n",
    "# And BS to parse the html\n",
    "soup = BeautifulSoup(c,\"html.parser\")\n",
    "\n",
    "# we print a heading three tag\n",
    "most_pop_last_week = soup.find('h3').text\n",
    "print(most_pop_last_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.kdnuggets.com/2018/02/top-news-week-0129-0204.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Simply and in short, natural language processing (NLP) is about developing applications and services that are able to understand human languages. We are talking here about practical examples of natural language processing (NLP) like speech recognition, speech translation, understanding complete sentences, understanding synonyms of matching words, and writing complete grammatically correct sentences and paragraphs.\n",
    "\n",
    "In Python, there are many libraries for dealing with language and textual data, we preview some of them:\n",
    " - [Natural language toolkit (NLTK](https://www.nltk.org): A library for general purpose processing and analysis of human language data.\n",
    " - [TextBlob](https://textblob.readthedocs.io/en/dev/):Built on top of NLTK above, this package provides similar natural language functionality\n",
    " - [spaCy](https://spacy.io): Optmised for large scale processing of natural language data.\n",
    " - [Stanford Core NLP](https://stanfordnlp.github.io/CoreNLP/): An old NLP package written in Java but it has some Python APIs such as [py-corenlp](https://github.com/smilli/py-corenlp/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A taste of NLTK on Twitter Data\n",
    "Lets quickly look at this twitter dataset from [datahack](https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/) just to demonstrate how language processing is possible in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, we have to import the package\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# When running for the first time, please uncomment line beloe to donwload the extra packages\n",
    "nltk.download('punkt') \n",
    "\n",
    "\n",
    "# path to data file\n",
    "twitter_data = '../data/twitter-dataset-from-datahack.csv'\n",
    "\n",
    "# Get CSV\n",
    "df_twitter = pd.read_csv(twitter_data)\n",
    "\n",
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.iloc[0].tweetb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.iloc[0].tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_tweet = df_twitter.iloc[0].tweet\n",
    "one_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.word_tokenize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(row):\n",
    "    print(row['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.apply(lambda x: print_row(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One preprocessing steps in NLP is tokenizing (converting sentences into separate words)\n",
    "df_twitter['tokens'] = df_twitter.apply(lambda x: nltk.word_tokenize(x['tweet']), axis=1)\n",
    "\n",
    "# Lets check the split tweets\n",
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Translation with TextBlob\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Translation is one of the common tasks in NLP. Many APIs provide translation, for example, you can use Google API to tranlate texts on demand for free or for a charge depending on the bulk of your translations. However, in Python the NLP libraries also enable you to translate as we will see in exmaple below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Install TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Navigate to the installers folder\n",
    "2. Navigate to sloria-TextBlob-e883b03 folder\n",
    "3. Do ```pip install .```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "chinese_blob = TextBlob(u\"美丽优于丑陋\")\n",
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_doc_title(file=None):\n",
    "    try:\n",
    "        open_file = open(file, mode='rb')\n",
    "        if file[-3:] == \"pdf\":\n",
    "            pdf_document = PyPDF2.PdfFileReader(open_file)\n",
    "            doc_info = pdf_document.documentInfo\n",
    "            title = doc_info[\"/Title\"]\n",
    "            \n",
    "            return title\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"../data/PDFs/Zambia Census 2020 Mapping-Copperbelt- v1.pdf\"\n",
    "open_file = open(pdf_file, mode='rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_document = PyPDF2.PdfFileReader(open_file)\n",
    "doc_info = pdf_document.documentInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(pdf_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_page_1 = pdf_document.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in pdfs_dir.iterdir():\n",
    "    #print(d)\n",
    "    title = get_doc_title(file=os.path.abspath(d))\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Python has many data visualisation tools, here are some of them:\n",
    "- [Matplotlib]() : this is the base plotting engine in Python. Most of the other packages are somehow based on it.\n",
    "- [Seaborn](): A relatively new packahe with more colourful plots\n",
    "- [Bokeh](): this is an interactive visualization library that targets modern web browsers for presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualisations with Bokeh\n",
    "\n",
    "The simple interactive example below has been copied from [Bokeh Documentation] (https://demo.bokehplots.com/apps/moviesfrom) for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "import numpy as np\n",
    "N = 4000\n",
    "x = np.random.random(size=N) * 100\n",
    "y = np.random.random(size=N) * 100\n",
    "radii = np.random.random(size=N) * 1.5\n",
    "colors = [\n",
    "    \"#%02x%02x%02x\" % (int(r), int(g), 150) for r, g in zip(50+2*x, 30+2*y)\n",
    "]\n",
    "\n",
    "TOOLS=\"hover,crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select,\"\n",
    "\n",
    "p = figure(tools=TOOLS)\n",
    "\n",
    "p.scatter(x, y, radius=radii,\n",
    "          fill_color=colors, fill_alpha=0.6,\n",
    "          line_color=None)\n",
    "\n",
    "output_file(\"color_scatter.html\", title=\"color_scatter.py example\")\n",
    "\n",
    "# please inspect the plot in the browser\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this tutorial, we previewed some of the essential packages in Python for doing data science with the intent to get excited to learn more. You can always learn more about any of the packages mentioned here by going to the documentation page linked or doing a Google search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/dunstanmatekenya/Downloads/BD_Students.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Name'], inplace=True)\n",
    "df['first'] = df.Name.apply(lambda x: x.split()[0].lower())\n",
    "df['last'] = df.Name.apply(lambda x: x.split()[-1].lower())\n",
    "df['name'] = df.apply(lambda x: x['first'] + \"_\" + x['last'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Email address', \t'Program'], inplace=True)\n",
    "df.to_csv('../DATASETS/usernames.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yvan_mugabowakigeli eunisse_mangaptche sergio_tinaharimanjaka anaclet_ukurikiyeyezu benon_hatangimana doricas_nyasomba fifen_hassan ladislas_nkurunziza adiza_sandah bien-aim\\x8e_kiakisolako callixte_ndizihiwe denyse_uwitonze didas_ntirabampa edison_muragijimana edissa_nyirarukundo gopina_gouletegome goudougna_mouldessou halluya_kouadio japhet_mugabo olivier_kanamugire omama_ibrahim yvette_dushime arnica_murebwayire bright_nuakoh clemence_ingabire henriette_dukuzimana jean_turikumwe lucie_umuhoza mariama_jammeh olamide_oseni salomey_frimpong yusuph_margwe jonas_niyitegeka m_uwanyirigira marka_ranambinintsoa miujiza_theophile'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lambda x,y: lambda z: 2*x*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yvan MUGABOWAKIGELI</td>\n",
       "      <td>yvan</td>\n",
       "      <td>mugabowakigeli</td>\n",
       "      <td>yvan_mugabowakigeli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eunisse Lopez NZETCHUEN MANGAPTCHE</td>\n",
       "      <td>eunisse</td>\n",
       "      <td>mangaptche</td>\n",
       "      <td>eunisse_mangaptche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sergio Germain TINAHARIMANJAKA</td>\n",
       "      <td>sergio</td>\n",
       "      <td>tinaharimanjaka</td>\n",
       "      <td>sergio_tinaharimanjaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anaclet UKURIKIYEYEZU</td>\n",
       "      <td>anaclet</td>\n",
       "      <td>ukurikiyeyezu</td>\n",
       "      <td>anaclet_ukurikiyeyezu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benon HATANGIMANA</td>\n",
       "      <td>benon</td>\n",
       "      <td>hatangimana</td>\n",
       "      <td>benon_hatangimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doricas NYASOMBA</td>\n",
       "      <td>doricas</td>\n",
       "      <td>nyasomba</td>\n",
       "      <td>doricas_nyasomba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fifen HASSAN</td>\n",
       "      <td>fifen</td>\n",
       "      <td>hassan</td>\n",
       "      <td>fifen_hassan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ladislas NKURUNZIZA</td>\n",
       "      <td>ladislas</td>\n",
       "      <td>nkurunziza</td>\n",
       "      <td>ladislas_nkurunziza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adiza SANDAH</td>\n",
       "      <td>adiza</td>\n",
       "      <td>sandah</td>\n",
       "      <td>adiza_sandah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bien-Aim Makimona KIAKISOLAKO</td>\n",
       "      <td>bien-aim</td>\n",
       "      <td>kiakisolako</td>\n",
       "      <td>bien-aim_kiakisolako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Callixte NDIZIHIWE</td>\n",
       "      <td>callixte</td>\n",
       "      <td>ndizihiwe</td>\n",
       "      <td>callixte_ndizihiwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Denyse UWITONZE</td>\n",
       "      <td>denyse</td>\n",
       "      <td>uwitonze</td>\n",
       "      <td>denyse_uwitonze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Didas NTIRABAMPA</td>\n",
       "      <td>didas</td>\n",
       "      <td>ntirabampa</td>\n",
       "      <td>didas_ntirabampa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Edison MURAGIJIMANA</td>\n",
       "      <td>edison</td>\n",
       "      <td>muragijimana</td>\n",
       "      <td>edison_muragijimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Edissa NYIRARUKUNDO</td>\n",
       "      <td>edissa</td>\n",
       "      <td>nyirarukundo</td>\n",
       "      <td>edissa_nyirarukundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gopina ASSANE GOULETEGOME</td>\n",
       "      <td>gopina</td>\n",
       "      <td>gouletegome</td>\n",
       "      <td>gopina_gouletegome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Goudougna MOULDESSOU</td>\n",
       "      <td>goudougna</td>\n",
       "      <td>mouldessou</td>\n",
       "      <td>goudougna_mouldessou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Halluya Harold Pasquerel Manoah KOUADIO</td>\n",
       "      <td>halluya</td>\n",
       "      <td>kouadio</td>\n",
       "      <td>halluya_kouadio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Japhet MUGABO</td>\n",
       "      <td>japhet</td>\n",
       "      <td>mugabo</td>\n",
       "      <td>japhet_mugabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Olivier KANAMUGIRE</td>\n",
       "      <td>olivier</td>\n",
       "      <td>kanamugire</td>\n",
       "      <td>olivier_kanamugire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Omama IBRAHIM</td>\n",
       "      <td>omama</td>\n",
       "      <td>ibrahim</td>\n",
       "      <td>omama_ibrahim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yvette DUSHIME</td>\n",
       "      <td>yvette</td>\n",
       "      <td>dushime</td>\n",
       "      <td>yvette_dushime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Arnica MUREBWAYIRE</td>\n",
       "      <td>arnica</td>\n",
       "      <td>murebwayire</td>\n",
       "      <td>arnica_murebwayire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bright Wiredu NUAKOH</td>\n",
       "      <td>bright</td>\n",
       "      <td>nuakoh</td>\n",
       "      <td>bright_nuakoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Clemence INGABIRE</td>\n",
       "      <td>clemence</td>\n",
       "      <td>ingabire</td>\n",
       "      <td>clemence_ingabire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Henriette DUKUZIMANA</td>\n",
       "      <td>henriette</td>\n",
       "      <td>dukuzimana</td>\n",
       "      <td>henriette_dukuzimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Jean Claude TURIKUMWE</td>\n",
       "      <td>jean</td>\n",
       "      <td>turikumwe</td>\n",
       "      <td>jean_turikumwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lucie UMUHOZA</td>\n",
       "      <td>lucie</td>\n",
       "      <td>umuhoza</td>\n",
       "      <td>lucie_umuhoza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mariama JAMMEH</td>\n",
       "      <td>mariama</td>\n",
       "      <td>jammeh</td>\n",
       "      <td>mariama_jammeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Olamide Samuel OSENI</td>\n",
       "      <td>olamide</td>\n",
       "      <td>oseni</td>\n",
       "      <td>olamide_oseni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Salomey Brago FRIMPONG</td>\n",
       "      <td>salomey</td>\n",
       "      <td>frimpong</td>\n",
       "      <td>salomey_frimpong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Yusuph Emanueli MARGWE</td>\n",
       "      <td>yusuph</td>\n",
       "      <td>margwe</td>\n",
       "      <td>yusuph_margwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jonas NIYITEGEKA</td>\n",
       "      <td>jonas</td>\n",
       "      <td>niyitegeka</td>\n",
       "      <td>jonas_niyitegeka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>M Josee UWANYIRIGIRA</td>\n",
       "      <td>m</td>\n",
       "      <td>uwanyirigira</td>\n",
       "      <td>m_uwanyirigira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Marka RANAMBININTSOA</td>\n",
       "      <td>marka</td>\n",
       "      <td>ranambinintsoa</td>\n",
       "      <td>marka_ranambinintsoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Miujiza Zirimwabagabo THEOPHILE</td>\n",
       "      <td>miujiza</td>\n",
       "      <td>theophile</td>\n",
       "      <td>miujiza_theophile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name      first             last  \\\n",
       "0                       Yvan MUGABOWAKIGELI       yvan   mugabowakigeli   \n",
       "1        Eunisse Lopez NZETCHUEN MANGAPTCHE    eunisse       mangaptche   \n",
       "2            Sergio Germain TINAHARIMANJAKA     sergio  tinaharimanjaka   \n",
       "3                     Anaclet UKURIKIYEYEZU    anaclet    ukurikiyeyezu   \n",
       "4                         Benon HATANGIMANA      benon      hatangimana   \n",
       "5                          Doricas NYASOMBA    doricas         nyasomba   \n",
       "6                             Fifen HASSAN       fifen           hassan   \n",
       "7                       Ladislas NKURUNZIZA   ladislas       nkurunziza   \n",
       "8                              Adiza SANDAH      adiza           sandah   \n",
       "9            Bien-Aim Makimona KIAKISOLAKO  bien-aim      kiakisolako   \n",
       "10                       Callixte NDIZIHIWE   callixte        ndizihiwe   \n",
       "11                          Denyse UWITONZE     denyse         uwitonze   \n",
       "12                         Didas NTIRABAMPA      didas       ntirabampa   \n",
       "13                      Edison MURAGIJIMANA     edison     muragijimana   \n",
       "14                      Edissa NYIRARUKUNDO     edissa     nyirarukundo   \n",
       "15                Gopina ASSANE GOULETEGOME     gopina      gouletegome   \n",
       "16                     Goudougna MOULDESSOU  goudougna       mouldessou   \n",
       "17  Halluya Harold Pasquerel Manoah KOUADIO    halluya          kouadio   \n",
       "18                            Japhet MUGABO     japhet           mugabo   \n",
       "19                       Olivier KANAMUGIRE    olivier       kanamugire   \n",
       "20                           Omama IBRAHIM       omama          ibrahim   \n",
       "21                           Yvette DUSHIME     yvette          dushime   \n",
       "22                      Arnica MUREBWAYIRE      arnica      murebwayire   \n",
       "23                     Bright Wiredu NUAKOH     bright           nuakoh   \n",
       "24                        Clemence INGABIRE   clemence         ingabire   \n",
       "25                     Henriette DUKUZIMANA  henriette       dukuzimana   \n",
       "26                    Jean Claude TURIKUMWE       jean        turikumwe   \n",
       "27                            Lucie UMUHOZA      lucie          umuhoza   \n",
       "28                           Mariama JAMMEH    mariama           jammeh   \n",
       "29                     Olamide Samuel OSENI    olamide            oseni   \n",
       "30                   Salomey Brago FRIMPONG    salomey         frimpong   \n",
       "31                   Yusuph Emanueli MARGWE     yusuph           margwe   \n",
       "32                         Jonas NIYITEGEKA      jonas       niyitegeka   \n",
       "33                     M Josee UWANYIRIGIRA          m     uwanyirigira   \n",
       "34                     Marka RANAMBININTSOA      marka   ranambinintsoa   \n",
       "35          Miujiza Zirimwabagabo THEOPHILE    miujiza        theophile   \n",
       "\n",
       "                      name  \n",
       "0      yvan_mugabowakigeli  \n",
       "1       eunisse_mangaptche  \n",
       "2   sergio_tinaharimanjaka  \n",
       "3    anaclet_ukurikiyeyezu  \n",
       "4        benon_hatangimana  \n",
       "5         doricas_nyasomba  \n",
       "6             fifen_hassan  \n",
       "7      ladislas_nkurunziza  \n",
       "8             adiza_sandah  \n",
       "9    bien-aim_kiakisolako  \n",
       "10      callixte_ndizihiwe  \n",
       "11         denyse_uwitonze  \n",
       "12        didas_ntirabampa  \n",
       "13     edison_muragijimana  \n",
       "14     edissa_nyirarukundo  \n",
       "15      gopina_gouletegome  \n",
       "16    goudougna_mouldessou  \n",
       "17         halluya_kouadio  \n",
       "18           japhet_mugabo  \n",
       "19      olivier_kanamugire  \n",
       "20           omama_ibrahim  \n",
       "21          yvette_dushime  \n",
       "22      arnica_murebwayire  \n",
       "23           bright_nuakoh  \n",
       "24       clemence_ingabire  \n",
       "25    henriette_dukuzimana  \n",
       "26          jean_turikumwe  \n",
       "27           lucie_umuhoza  \n",
       "28          mariama_jammeh  \n",
       "29           olamide_oseni  \n",
       "30        salomey_frimpong  \n",
       "31           yusuph_margwe  \n",
       "32        jonas_niyitegeka  \n",
       "33          m_uwanyirigira  \n",
       "34    marka_ranambinintsoa  \n",
       "35       miujiza_theophile  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
